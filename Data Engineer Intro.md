I am a **Data Engineer** with over 3 years of experience in building and maintaining data solutions, focusing on technologies like **Databricks**, **Azure Data Factory**, **ADLS Blob Storage**, **PySpark**, **SQL**, and **Python**. My expertise includes developing scalable data pipelines to automate data ingestion, transformation, and loading for large datasets, both in batch and real-time. I have implemented efficient data processing workflows in **PySpark** within **Databricks**, leveraging **ADLS Blob Storage** to handle large-scale data efficiently.

I have been responsible for writing optimized SQL queries for data extraction and transformation from **ADLS Blob Storage**, ensuring high performance for reporting and analytics. In addition, I have built data workflows in **Azure Data Factory** to move data between **ADLS** and various other sources, automating the entire process. Utilizing **Python**, I have scripted and automated transformations on datasets, improving pipeline efficiency while reducing manual intervention.

Throughout my projects, I have ensured smooth collaboration by managing code versioning with **GitHub** and tracking tasks using **Jira** in an agile environment. I have also monitored and optimized **Databricks** clusters for better resource utilization, minimizing costs while ensuring high performance. Furthermore, I have collaborated with cross-functional teams to implement best practices for data storage and processing in **ADLS Blob Storage**, maintaining data quality, accuracy, and consistency across various layers in the architecture.



- Developed scalable data pipelines in **Databricks** and **Azure Data Factory**, automating data ingestion, transformation, and loading for large datasets stored in **ADLS Blob Storage**, handling both batch and real-time processing.

- Implemented data processing workflows in **PySpark** within **Databricks** to read, process, and write large datasets efficiently to and from **ADLS Blob Storage**.

- Created optimized **SQL** queries for data extraction and transformation from **ADLS Blob Storage**, ensuring high performance for downstream reporting and analytics.

- Built and managed workflows in **Azure Data Factory** to move data between **ADLS Blob Storage** and various other sources and destinations, automating data flows seamlessly.

- Utilized **Python** for scripting and automating data transformations on datasets stored in **ADLS Blob Storage**, enhancing pipeline efficiency and reducing manual tasks.

- Monitored and optimized **Databricks** jobs, improving cluster utilization and minimizing the cost of processing large datasets stored in **ADLS Blob Storage**.

- Managed code versioning using **GitHub**, ensuring smooth collaboration and proper version control across multiple development teams.

- Used **Jira** for agile project tracking and task management, contributing to the successful and timely delivery of data engineering projects.

- Collaborated with cross-functional teams to implement best practices for storing, organizing, and processing data in **ADLS Blob Storage**, ensuring optimal data access and retrieval performance.

- Tested and validated data pipelines, ensuring accurate data movement between **ADLS Blob Storage** and target systems while maintaining d
